{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29379dd0",
   "metadata": {},
   "source": [
    "# IMPORT LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bright-original",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_rows', 50)\n",
    "pd.set_option('display.max_columns', 50)\n",
    "\n",
    "# data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "plt.rcParams['figure.figsize'] = 12,6\n",
    "sns.set_style('darkgrid')\n",
    "%matplotlib inline\n",
    "\n",
    "# preprocessing\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, cross_validate, StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# machine learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score, precision_recall_curve, f1_score, fbeta_score\n",
    "\n",
    "# hyperparameter tuning\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "# miscellaneous\n",
    "import math\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252b63f8",
   "metadata": {},
   "source": [
    "# IMPORT DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "operating-reserve",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>-0.551600</td>\n",
       "      <td>-0.617801</td>\n",
       "      <td>-0.991390</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>1.468177</td>\n",
       "      <td>-0.470401</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>1.612727</td>\n",
       "      <td>1.065235</td>\n",
       "      <td>0.489095</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>0.635558</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>-0.114805</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>0.624501</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>0.717293</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>2.345865</td>\n",
       "      <td>-2.890083</td>\n",
       "      <td>1.109969</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>-0.226487</td>\n",
       "      <td>0.178228</td>\n",
       "      <td>0.507757</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>-0.631418</td>\n",
       "      <td>-1.059647</td>\n",
       "      <td>-0.684093</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>-0.822843</td>\n",
       "      <td>0.538196</td>\n",
       "      <td>1.345852</td>\n",
       "      <td>-1.119670</td>\n",
       "      <td>0.175121</td>\n",
       "      <td>-0.451449</td>\n",
       "      <td>-0.237033</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.425966</td>\n",
       "      <td>0.960523</td>\n",
       "      <td>1.141109</td>\n",
       "      <td>-0.168252</td>\n",
       "      <td>0.420987</td>\n",
       "      <td>-0.029728</td>\n",
       "      <td>0.476201</td>\n",
       "      <td>0.260314</td>\n",
       "      <td>-0.568671</td>\n",
       "      <td>-0.371407</td>\n",
       "      <td>1.341262</td>\n",
       "      <td>0.359894</td>\n",
       "      <td>-0.358091</td>\n",
       "      <td>-0.137134</td>\n",
       "      <td>0.517617</td>\n",
       "      <td>0.401726</td>\n",
       "      <td>-0.058133</td>\n",
       "      <td>0.068653</td>\n",
       "      <td>-0.033194</td>\n",
       "      <td>0.084968</td>\n",
       "      <td>-0.208254</td>\n",
       "      <td>-0.559825</td>\n",
       "      <td>-0.026398</td>\n",
       "      <td>-0.371427</td>\n",
       "      <td>-0.232794</td>\n",
       "      <td>0.105915</td>\n",
       "      <td>0.253844</td>\n",
       "      <td>0.081080</td>\n",
       "      <td>3.67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "5   2.0 -0.425966  0.960523  1.141109 -0.168252  0.420987 -0.029728  0.476201   \n",
       "\n",
       "         V8        V9       V10       V11       V12       V13       V14  \\\n",
       "0  0.098698  0.363787  0.090794 -0.551600 -0.617801 -0.991390 -0.311169   \n",
       "1  0.085102 -0.255425 -0.166974  1.612727  1.065235  0.489095 -0.143772   \n",
       "2  0.247676 -1.514654  0.207643  0.624501  0.066084  0.717293 -0.165946   \n",
       "3  0.377436 -1.387024 -0.054952 -0.226487  0.178228  0.507757 -0.287924   \n",
       "4 -0.270533  0.817739  0.753074 -0.822843  0.538196  1.345852 -1.119670   \n",
       "5  0.260314 -0.568671 -0.371407  1.341262  0.359894 -0.358091 -0.137134   \n",
       "\n",
       "        V15       V16       V17       V18       V19       V20       V21  \\\n",
       "0  1.468177 -0.470401  0.207971  0.025791  0.403993  0.251412 -0.018307   \n",
       "1  0.635558  0.463917 -0.114805 -0.183361 -0.145783 -0.069083 -0.225775   \n",
       "2  2.345865 -2.890083  1.109969 -0.121359 -2.261857  0.524980  0.247998   \n",
       "3 -0.631418 -1.059647 -0.684093  1.965775 -1.232622 -0.208038 -0.108300   \n",
       "4  0.175121 -0.451449 -0.237033 -0.038195  0.803487  0.408542 -0.009431   \n",
       "5  0.517617  0.401726 -0.058133  0.068653 -0.033194  0.084968 -0.208254   \n",
       "\n",
       "        V22       V23       V24       V25       V26       V27       V28  \\\n",
       "0  0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053   \n",
       "1 -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724   \n",
       "2  0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752   \n",
       "3  0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458   \n",
       "4  0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   \n",
       "5 -0.559825 -0.026398 -0.371427 -0.232794  0.105915  0.253844  0.081080   \n",
       "\n",
       "   Amount  Class  \n",
       "0  149.62      0  \n",
       "1    2.69      0  \n",
       "2  378.66      0  \n",
       "3  123.50      0  \n",
       "4   69.99      0  \n",
       "5    3.67      0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('creditcard.csv')\n",
    "df.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19c54989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7472da9",
   "metadata": {},
   "source": [
    "# CHECK FOR MISSING VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bee164db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0.0\n",
       "V1        0.0\n",
       "V2        0.0\n",
       "V3        0.0\n",
       "V4        0.0\n",
       "V5        0.0\n",
       "V6        0.0\n",
       "V7        0.0\n",
       "V8        0.0\n",
       "V9        0.0\n",
       "V10       0.0\n",
       "V11       0.0\n",
       "V12       0.0\n",
       "V13       0.0\n",
       "V14       0.0\n",
       "V15       0.0\n",
       "V16       0.0\n",
       "V17       0.0\n",
       "V18       0.0\n",
       "V19       0.0\n",
       "V20       0.0\n",
       "V21       0.0\n",
       "V22       0.0\n",
       "V23       0.0\n",
       "V24       0.0\n",
       "V25       0.0\n",
       "V26       0.0\n",
       "V27       0.0\n",
       "V28       0.0\n",
       "Amount    0.0\n",
       "Class     0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum() / len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff978af0",
   "metadata": {},
   "source": [
    "# DISTRIBUTION OF AMOUNT OF FRAUD TRANSACTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e93bb6b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.displot(df[df['Class']==1]['Amount'], height=5, aspect=2)\n",
    "plt.xlabel('Amount', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d23ebff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.25"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_cost = round(df[df['Class']==1]['Amount'].median(), 2)\n",
    "fraud_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f24126d",
   "metadata": {},
   "source": [
    "# MODEL DEVELOPMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1ae8ee",
   "metadata": {},
   "source": [
    "## 1. Model preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "suspected-beach",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_models():\n",
    "    models = {}\n",
    "    models['Logistic Regression'] = LogisticRegression(max_iter=5000)\n",
    "    models['K-Nearest Neighbors'] = KNeighborsClassifier()\n",
    "    models['Support Vector Machines'] = SVC()\n",
    "    models['Decision Tree'] = DecisionTreeClassifier()\n",
    "    models['Naive Bayes'] = GaussianNB()\n",
    "    models['Random Forest'] = RandomForestClassifier()\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "psychological-burning",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X, y, metrics='accuracy'):\n",
    "    scaler = StandardScaler()\n",
    "    pipeline = Pipeline(steps=[('scaler', scaler), ('model', model)])\n",
    "    cv = StratifiedKFold(5, shuffle=True, random_state=143)\n",
    "    scores = cross_validate(pipeline, X, y, cv=cv, scoring=metrics)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1f76d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def false_positive(estimator, X, y):\n",
    "    predictions = estimator.predict(X)\n",
    "    cm = confusion_matrix(y, predictions)\n",
    "    return cm[0][1]\n",
    "\n",
    "def false_negative(estimator, X, y):\n",
    "    predictions = estimator.predict(X)\n",
    "    cm = confusion_matrix(y, predictions)\n",
    "    return cm[1][0]\n",
    "\n",
    "def true_positive(estimator, X, y):\n",
    "    predictions = estimator.predict(X)\n",
    "    cm = confusion_matrix(y, predictions)\n",
    "    return cm[1][1]\n",
    "\n",
    "def f2_score(estimator, X, y):\n",
    "    predictions = estimator.predict(X)\n",
    "    return fbeta_score(y, predictions, beta=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e28986f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[:,1:]\n",
    "X = df.drop('Class', axis=1)\n",
    "y = df['Class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=143)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34af5e4",
   "metadata": {},
   "source": [
    "## 2. Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "legitimate-money",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Initializing Logistic Regression ---\n",
      "--- Logistic Regression done! ---\n",
      "--- Initializing K-Nearest Neighbors ---\n",
      "--- K-Nearest Neighbors done! ---\n",
      "--- Initializing Support Vector Machines ---\n",
      "--- Support Vector Machines done! ---\n",
      "--- Initializing Decision Tree ---\n",
      "--- Decision Tree done! ---\n",
      "--- Initializing Naive Bayes ---\n",
      "--- Naive Bayes done! ---\n",
      "--- Initializing Random Forest ---\n",
      "--- Random Forest done! ---\n"
     ]
    }
   ],
   "source": [
    "names = []\n",
    "results = []\n",
    "\n",
    "scoring = {'fp':false_positive,\n",
    "           'fn':false_negative,\n",
    "           'recall': 'recall',\n",
    "           'precision': 'precision',\n",
    "           'f1_score': 'f1',\n",
    "           'f2_score':f2_score}\n",
    "\n",
    "for name, model in create_models().items():\n",
    "    print(f'--- Initializing {name} ---')\n",
    "    scores = evaluate_model(model, X_train, y_train, scoring)\n",
    "    names.append(name)\n",
    "    results.append(scores)\n",
    "    print(f'--- {name} done! ---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1613606b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>False positive</th>\n",
       "      <th>False negative</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>F2-score</th>\n",
       "      <th>Money loss (RM)</th>\n",
       "      <th>Time to compute (seconds)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>0.781212</td>\n",
       "      <td>0.935694</td>\n",
       "      <td>0.850751</td>\n",
       "      <td>0.807474</td>\n",
       "      <td>129.50</td>\n",
       "      <td>698.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K-Nearest Neighbors</th>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>0.769091</td>\n",
       "      <td>0.919808</td>\n",
       "      <td>0.836921</td>\n",
       "      <td>0.794706</td>\n",
       "      <td>138.75</td>\n",
       "      <td>3560.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>0.753939</td>\n",
       "      <td>0.767595</td>\n",
       "      <td>0.759584</td>\n",
       "      <td>0.755924</td>\n",
       "      <td>148.00</td>\n",
       "      <td>71.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Machines</th>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.644336</td>\n",
       "      <td>0.946674</td>\n",
       "      <td>0.765423</td>\n",
       "      <td>0.687665</td>\n",
       "      <td>212.75</td>\n",
       "      <td>1309.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>0.620326</td>\n",
       "      <td>0.867202</td>\n",
       "      <td>0.721762</td>\n",
       "      <td>0.657042</td>\n",
       "      <td>231.25</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>892</td>\n",
       "      <td>10</td>\n",
       "      <td>0.842005</td>\n",
       "      <td>0.058520</td>\n",
       "      <td>0.109428</td>\n",
       "      <td>0.228914</td>\n",
       "      <td>92.50</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         False positive  False negative    Recall  Precision  \\\n",
       "Random Forest                         4              14  0.781212   0.935694   \n",
       "K-Nearest Neighbors                   5              15  0.769091   0.919808   \n",
       "Decision Tree                        15              16  0.753939   0.767595   \n",
       "Support Vector Machines               2              23  0.644336   0.946674   \n",
       "Logistic Regression                   6              25  0.620326   0.867202   \n",
       "Naive Bayes                         892              10  0.842005   0.058520   \n",
       "\n",
       "                         F1-score  F2-score  Money loss (RM)  \\\n",
       "Random Forest            0.850751  0.807474           129.50   \n",
       "K-Nearest Neighbors      0.836921  0.794706           138.75   \n",
       "Decision Tree            0.759584  0.755924           148.00   \n",
       "Support Vector Machines  0.765423  0.687665           212.75   \n",
       "Logistic Regression      0.721762  0.657042           231.25   \n",
       "Naive Bayes              0.109428  0.228914            92.50   \n",
       "\n",
       "                         Time to compute (seconds)  \n",
       "Random Forest                                698.0  \n",
       "K-Nearest Neighbors                         3560.9  \n",
       "Decision Tree                                 71.8  \n",
       "Support Vector Machines                     1309.6  \n",
       "Logistic Regression                            7.6  \n",
       "Naive Bayes                                    2.4  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_fp = []\n",
    "test_fn = []\n",
    "test_recall = []\n",
    "test_precision = []\n",
    "test_f1 = []\n",
    "test_f2 = []\n",
    "time_taken = []\n",
    "\n",
    "for i in range(len(results)):\n",
    "    test_fp.append(round(results[i]['test_fp'].mean()))\n",
    "\n",
    "for i in range(len(results)):\n",
    "    test_fn.append(round(results[i]['test_fn'].mean()))\n",
    "\n",
    "for i in range(len(results)):\n",
    "    test_recall.append(results[i]['test_recall'].mean())\n",
    "\n",
    "for i in range(len(results)):\n",
    "    test_precision.append(results[i]['test_precision'].mean())\n",
    "\n",
    "for i in range(len(results)):\n",
    "    test_f1.append(results[i]['test_f1_score'].mean())\n",
    "\n",
    "for i in range(len(results)):\n",
    "    test_f2.append(results[i]['test_f2_score'].mean())\n",
    "\n",
    "for i in range(len(results)):\n",
    "    time_taken.append(round(results[i]['score_time'].sum(), 1) + round(results[i]['fit_time'].sum(), 1))\n",
    "\n",
    "test_fn = pd.Series(test_fn, name='False negative')\n",
    "test_fp = pd.Series(test_fp, name='False positive')\n",
    "test_recall = pd.Series(test_recall, name='Recall')\n",
    "test_precision = pd.Series(test_precision, name='Precision')\n",
    "test_f1 = pd.Series(test_f1, name='F1-score')\n",
    "test_f2 = pd.Series(test_f2, name='F2-score')\n",
    "time_taken = pd.Series(time_taken, name='Time to compute (seconds)')\n",
    "\n",
    "df_result = pd.concat([test_fp, test_fn, test_recall, test_precision, test_f1, test_f2, time_taken], axis=1)\n",
    "df_result.index = names\n",
    "df_result['Money loss (RM)'] = round(fraud_cost * df_result['False negative'], 2)\n",
    "df_result = df_result.iloc[:,[0, 1, 2, 3, 4, 5, 7, 6]]\n",
    "df_result.sort_values(['F2-score'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0436aa6b",
   "metadata": {},
   "source": [
    "## 3. Model training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3507fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2cb562d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=143)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest = RandomForestClassifier(random_state=143)\n",
    "forest.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a7ffb72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[85273,     7],\n",
       "       [   43,   120]], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = forest.predict(X_test_scaled)\n",
    "confusion_matrix(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8648ce44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7702182284980743"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fbeta_score(y_test, predictions, beta=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e2567f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost: RM 397.75\n"
     ]
    }
   ],
   "source": [
    "(tn, fp), (fn, tp) = confusion_matrix(y_test, predictions)\n",
    "\n",
    "print(f'Cost: RM {round(fn * fraud_cost, 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54697afc",
   "metadata": {},
   "source": [
    "## 4. Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f80008e2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | max_depth | max_fe... | min_sa... | n_esti... |\n",
      "-------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.8353  \u001b[0m | \u001b[0m 23.44   \u001b[0m | \u001b[0m 0.406   \u001b[0m | \u001b[0m 29.15   \u001b[0m | \u001b[0m 452.7   \u001b[0m |\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.8563  \u001b[0m | \u001b[95m 19.21   \u001b[0m | \u001b[95m 0.8932  \u001b[0m | \u001b[95m 3.922   \u001b[0m | \u001b[95m 58.34   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.8141  \u001b[0m | \u001b[0m 9.981   \u001b[0m | \u001b[0m 0.2505  \u001b[0m | \u001b[0m 58.2    \u001b[0m | \u001b[0m 103.7   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.8117  \u001b[0m | \u001b[0m 7.239   \u001b[0m | \u001b[0m 0.3517  \u001b[0m | \u001b[0m 37.34   \u001b[0m | \u001b[0m 117.0   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.8541  \u001b[0m | \u001b[0m 19.31   \u001b[0m | \u001b[0m 0.3993  \u001b[0m | \u001b[0m 17.18   \u001b[0m | \u001b[0m 138.0   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.8369  \u001b[0m | \u001b[0m 21.55   \u001b[0m | \u001b[0m 0.1797  \u001b[0m | \u001b[0m 14.78   \u001b[0m | \u001b[0m 85.31   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.8434  \u001b[0m | \u001b[0m 9.239   \u001b[0m | \u001b[0m 0.6577  \u001b[0m | \u001b[0m 25.08   \u001b[0m | \u001b[0m 963.9   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.8159  \u001b[0m | \u001b[0m 27.41   \u001b[0m | \u001b[0m 0.3296  \u001b[0m | \u001b[0m 49.94   \u001b[0m | \u001b[0m 839.3   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.8338  \u001b[0m | \u001b[0m 5.048   \u001b[0m | \u001b[0m 0.6119  \u001b[0m | \u001b[0m 12.53   \u001b[0m | \u001b[0m 79.01   \u001b[0m |\n",
      "| \u001b[95m 10      \u001b[0m | \u001b[95m 0.8618  \u001b[0m | \u001b[95m 25.78   \u001b[0m | \u001b[95m 0.5386  \u001b[0m | \u001b[95m 13.83   \u001b[0m | \u001b[95m 489.9   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.8323  \u001b[0m | \u001b[0m 23.31   \u001b[0m | \u001b[0m 0.2497  \u001b[0m | \u001b[0m 19.29   \u001b[0m | \u001b[0m 809.4   \u001b[0m |\n",
      "| \u001b[95m 12      \u001b[0m | \u001b[95m 0.8671  \u001b[0m | \u001b[95m 24.69   \u001b[0m | \u001b[95m 0.6881  \u001b[0m | \u001b[95m 4.492   \u001b[0m | \u001b[95m 737.7   \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.8315  \u001b[0m | \u001b[0m 10.64   \u001b[0m | \u001b[0m 0.4693  \u001b[0m | \u001b[0m 34.49   \u001b[0m | \u001b[0m 353.4   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.8583  \u001b[0m | \u001b[0m 12.41   \u001b[0m | \u001b[0m 0.6464  \u001b[0m | \u001b[0m 16.61   \u001b[0m | \u001b[0m 971.0   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.8488  \u001b[0m | \u001b[0m 27.76   \u001b[0m | \u001b[0m 0.2284  \u001b[0m | \u001b[0m 10.68   \u001b[0m | \u001b[0m 526.9   \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.851   \u001b[0m | \u001b[0m 29.29   \u001b[0m | \u001b[0m 0.6618  \u001b[0m | \u001b[0m 21.15   \u001b[0m | \u001b[0m 209.9   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.8407  \u001b[0m | \u001b[0m 8.864   \u001b[0m | \u001b[0m 0.4779  \u001b[0m | \u001b[0m 20.0    \u001b[0m | \u001b[0m 313.4   \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.8545  \u001b[0m | \u001b[0m 19.76   \u001b[0m | \u001b[0m 0.8685  \u001b[0m | \u001b[0m 7.391   \u001b[0m | \u001b[0m 113.9   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.822   \u001b[0m | \u001b[0m 14.42   \u001b[0m | \u001b[0m 0.7387  \u001b[0m | \u001b[0m 39.01   \u001b[0m | \u001b[0m 304.8   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.8396  \u001b[0m | \u001b[0m 8.713   \u001b[0m | \u001b[0m 0.6038  \u001b[0m | \u001b[0m 31.95   \u001b[0m | \u001b[0m 535.5   \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.8225  \u001b[0m | \u001b[0m 12.71   \u001b[0m | \u001b[0m 0.1801  \u001b[0m | \u001b[0m 32.33   \u001b[0m | \u001b[0m 637.8   \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 0.8549  \u001b[0m | \u001b[0m 24.09   \u001b[0m | \u001b[0m 0.6042  \u001b[0m | \u001b[0m 21.41   \u001b[0m | \u001b[0m 450.8   \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 0.8332  \u001b[0m | \u001b[0m 28.35   \u001b[0m | \u001b[0m 0.4858  \u001b[0m | \u001b[0m 29.1    \u001b[0m | \u001b[0m 735.9   \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 0.8214  \u001b[0m | \u001b[0m 9.313   \u001b[0m | \u001b[0m 0.528   \u001b[0m | \u001b[0m 36.66   \u001b[0m | \u001b[0m 826.7   \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m 0.8052  \u001b[0m | \u001b[0m 11.69   \u001b[0m | \u001b[0m 0.1682  \u001b[0m | \u001b[0m 55.24   \u001b[0m | \u001b[0m 971.1   \u001b[0m |\n",
      "| \u001b[95m 26      \u001b[0m | \u001b[95m 0.8675  \u001b[0m | \u001b[95m 10.42   \u001b[0m | \u001b[95m 0.7467  \u001b[0m | \u001b[95m 6.026   \u001b[0m | \u001b[95m 261.7   \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m 0.8508  \u001b[0m | \u001b[0m 28.07   \u001b[0m | \u001b[0m 0.9282  \u001b[0m | \u001b[0m 21.26   \u001b[0m | \u001b[0m 223.3   \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m 0.8157  \u001b[0m | \u001b[0m 8.159   \u001b[0m | \u001b[0m 0.5981  \u001b[0m | \u001b[0m 40.3    \u001b[0m | \u001b[0m 865.6   \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m 0.7767  \u001b[0m | \u001b[0m 19.86   \u001b[0m | \u001b[0m 0.1003  \u001b[0m | \u001b[0m 30.27   \u001b[0m | \u001b[0m 201.8   \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m 0.8147  \u001b[0m | \u001b[0m 14.51   \u001b[0m | \u001b[0m 0.2792  \u001b[0m | \u001b[0m 56.7    \u001b[0m | \u001b[0m 415.4   \u001b[0m |\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m 0.8555  \u001b[0m | \u001b[0m 7.309   \u001b[0m | \u001b[0m 0.6273  \u001b[0m | \u001b[0m 7.761   \u001b[0m | \u001b[0m 259.1   \u001b[0m |\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m 0.861   \u001b[0m | \u001b[0m 16.98   \u001b[0m | \u001b[0m 0.918   \u001b[0m | \u001b[0m 7.645   \u001b[0m | \u001b[0m 261.6   \u001b[0m |\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m 0.8647  \u001b[0m | \u001b[0m 10.04   \u001b[0m | \u001b[0m 0.7655  \u001b[0m | \u001b[0m 4.873   \u001b[0m | \u001b[0m 270.2   \u001b[0m |\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m 0.8646  \u001b[0m | \u001b[0m 14.36   \u001b[0m | \u001b[0m 0.7544  \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 738.0   \u001b[0m |\n",
      "| \u001b[0m 35      \u001b[0m | \u001b[0m 0.8643  \u001b[0m | \u001b[0m 20.71   \u001b[0m | \u001b[0m 0.9055  \u001b[0m | \u001b[0m 2.626   \u001b[0m | \u001b[0m 749.9   \u001b[0m |\n",
      "=========================================================================\n"
     ]
    }
   ],
   "source": [
    "def estimator(max_depth, min_samples_split, max_features, n_estimators):\n",
    "    params = {}\n",
    "    params['max_depth'] = round(max_depth)\n",
    "    params['min_samples_split'] = round(min_samples_split)\n",
    "    params['max_features'] = round(max_features, 1)\n",
    "    params['n_estimators'] = round(n_estimators)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    cv = StratifiedKFold(5, shuffle=True, random_state=143)\n",
    "    \n",
    "    model = RandomForestClassifier(random_state=143, **params)\n",
    "    pipeline = Pipeline(steps=[('scaler', scaler), ('model', model)])\n",
    "    \n",
    "    score = cross_val_score(pipeline, X_train, y_train, scoring='f1', cv=cv).mean()\n",
    "    return score\n",
    "\n",
    "params_bounds = {\n",
    "    'max_depth':(5, 30),\n",
    "    'min_samples_split':(2, 60),\n",
    "    'max_features':(0.1, 1.0),\n",
    "    'n_estimators':(50, 1000),\n",
    "}\n",
    "\n",
    "forest_bo = BayesianOptimization(estimator, params_bounds, random_state=143)\n",
    "forest_bo.maximize(init_points=30, n_iter=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "76ed561c",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_forest = forest_bo.max['params']\n",
    "params_forest['max_depth'] = round(params_forest['max_depth'])\n",
    "params_forest['min_samples_split'] = round(params_forest['min_samples_split'])\n",
    "params_forest['max_features'] = round(params_forest['max_features'], 1)\n",
    "params_forest['n_estimators'] = round(params_forest['n_estimators'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "493d79ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 10,\n",
       " 'max_features': 0.7,\n",
       " 'min_samples_split': 6,\n",
       " 'n_estimators': 262}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a44f53",
   "metadata": {},
   "source": [
    "## 5. Tune the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2ed333d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=10, max_features=0.7, min_samples_split=6,\n",
       "                       n_estimators=262, random_state=143)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest = RandomForestClassifier(random_state=143, **params_forest)\n",
    "forest.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eaddfc5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[85273,     7],\n",
       "       [   40,   123]], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = forest.predict(X_test_scaled)\n",
    "confusion_matrix(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fb993f82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7864450127877238"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fbeta_score(y_test, predictions, beta=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ebabdc38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost: RM 370.0\n"
     ]
    }
   ],
   "source": [
    "(tn, fp), (fn, tp) = confusion_matrix(y_test, predictions)\n",
    "\n",
    "print(f'Cost: RM {round(fn * fraud_cost, 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c526a4",
   "metadata": {},
   "source": [
    "# IMPLEMENTATION OF THRESHOLD ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aa5d338c",
   "metadata": {},
   "outputs": [],
   "source": [
    "proba = forest.predict_proba(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ab534fde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAs8AAAGDCAYAAADUAP09AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAtdklEQVR4nO3deZwkdX3/8Vd3z8zO3rOwiwssglwfEBHkkENQURBFUdSfGolGUVQ0Gs8oUX8eEWNiPKJGUDCKSTyiEYJEgweeXOHniVxfWUDua3fZe3d2p6d/f1TNbO8wM1vLTk33TL+ej8c8uutbNVWfni+zvOs736qqNBoNJEmSJG1btdUFSJIkSVOF4VmSJEkqyPAsSZIkFWR4liRJkgoyPEuSJEkFGZ4lSZKkgrpaXYAkba+I+BOwZ1PTILAGuBo4O6X0+5KOuxdwO3B8SumKbWz7dOCnwB4ppbtLrqdZA1gL3AB8IKX0ozKOPUotT6fp8+Z99KWU0jnjfM9+wHuAZwGLgHuAbwN/n1JaVXrRkvQoOPIsaar6B2DX/GsP4BnAPOCHETG3pGPelR/vfwtse1W+7b0l1dLsBWz5WexOFkY3AN+NiD3H+8ZWycP2b4AFwJ8DjwfeBrwQuDwi5rSsOEkahyPPkqaqtSml+5uW742Id5GF1mcAl0z0AVNKdeD+bW6Ybbup6LYTYMWIn8V9EfEq4E6yYP3ZSaqjkIjoBb4GfD+l9LKmVbdHxHXAH4G/JDtBkqS2YniWNJ0M5K/9ABHRAD4CvCZvPyJf90myUFkBrgHenlJKQzuJiFcC7wb2Be4APpZS+urIaRsRcXS+r0OBjcD3gbemlFaMMo1hFvAB4M+AxcDvgfemlC7Pj3khUAfWkY3E1oEfAm9MKa15FD+L/vx1c9PnOp4skD4JuA/4D+DDKaWN+fq5wN8D/weYRXYi8lcppRQRVeC9wKvIpsysBy4HzkopPbSdtZ0K7EbWN1tJKd0ZEc8AluY1fQh4RUpp36bPMdzW1CfvIxu5Xg6szHaVXt30PS8FLgQWp5RWR8TrgHcBj82P9YmU0le383NI6kBO25A0LUTE3mTB7z6y0DfkdcDzgBcBD5AF3N2Ak4HjyMLxFRGxc76flwFfBr4EHAx8AvhSRDxrxPFqwHfJAuRBwCnAkfn2o/km8FLgDWRh+xrgsog4qmmbVwA14FjgzWQh9q3b9YPIatsF+BzZ3Ofv5m2HAj8ALso/15lkIfa8pm/9FvBM4OVkJxprgR9ERDfwjryWtwD75dscRxZat9fhZH85uH60lSmlq1JKD27nPl8OPJXsxOMC4IX5CPeQ04GL8+D8RuCjZLU/geyE4jP5aL0kjcuRZ0lT1f+NiLPz993512+BF6WUVjdtd2FK6XcAEXEiWcDdqWmbN0bEM4HXAx8jG738WkrpM/n6pfn825GDDfOBhWRTM+5IKf0pIl4I9IwsNCIeTxZUT04p/TBvfmsenN8FvCRvW0420lsHUkScDhxT4Gfxw4gYzN/XyEbUrwCemlK6J29/F/C9lNJQuF8aEW8gO3F4L9l88WcDJ6SUfpbX/Xqy0eadgQS8KqV0Wf79d0TEZWRBfHstACb6gsB/TindDBARt5CdPJwCXBQRC4DnAM/Pt30f2Yj7f+bLt+Zzw98LOPosaVyGZ0lT1eeBc/P3A8DyMaY33Nb0/klk4fLeiGjephc4MH9/MPBvzStTSv8Ew3e3GGpbERGfzOv4cET8CLiUbPR2pCfkr1eOaP8l2aj4kFvz4DxkJdkFgETE/wDHN617DtkFjABnAL8GZgPvJBs9/khK6bdN2z8J2C8i1ja1VfLXA4Gd8vfXNn3G5fn+AC6NiGMi4qNAAAfk3/fLUT7vtiwDFkREJaXUeBTfP5rhfk4prYmIi8lGoy8iOzlZBvw4IhaR/Uw/ERHNc6q7gK6I6Mnnq0vSqAzPkqaqFSmlpQW229D0fhOwAjhqlO2GQuXmUdaNKqX01xHxeeC5ZHe4+ArZ1Ivnjth0Y/5aGdFeG3G8fh5p6HvOBGY2td8DPGbo/dDPIp968F2ysHt4SumWfJtNZKOqo12Edx9w4ijtwyLifcDfkH3G/wH+jmwax6O5m8fVZKO8BwPXjXKsfwTWpZQ+NMb3j/b/rg0jlr9KdreRuWRTNr6WUqpHxFAwfgvws1H2MzBKmyQNMzxL6iQ3kI+wNoXNGtmdHy4iGzW+iWy+77CI+FeyUeBPNbXtQzYV4u0ppc8Dn88vSvuPfM7xyOMCPIVs3jFNyzcWKbxp+kVzXaNt14iIM/P9fjUinpKP7t4AHNh8whERx5DdZ/ksss8N2Wf/Rb5+HtnFdC8im87ygZRS889gP7bjZKPJj8juBPJ+snngzZ9pX+BNZFNoIAv9I289uF+BY1xONtr8GrIR+zcDpJRWRcQ9wF4jfhZnAYemlM7a7k8jqaMYniV1ksvJLtT7VkS8lewCwrPJ5iP/bb7Nx/P115KFvGeQ/fn/OSP2tQx4GTAjIj5ONkL8MuDWfN2wlNKtEfFN4Lw8pN1JNsf6cLJQOqFSSg/kt+37MvBGsukt/wD8JiI+BZxPNmr9JbJR6/uB+yPiEuDc/IK6h8guqlsF/L98+eSI+D7ZiPkbyeZjF7nn9cj6+vOA/92I+E/g02Sj30eSXfR5PVtOVK4GPhoRbwP+i6wfngOMe0FhSmkwIv6d7I4evxtxceI5wKci4k6y/yaOyo/38e39LJI6j3fbkNQx8hHY08hGYS8hu8Bwf+DZKaUb823+i+wew+/It3sb8MqU0o9H7GsVWYjbhyxAXks2d/qUlNIgj/Q64DLg38keDnIU8KyU0tUT+Rmb6vsKWTD8WEQsSSn9gWw6yVOA35GNsv+c7KEkQ16df45LyD5TD9nPph/4C6CP7Gf2I7KLCM8GHp/fhm976/tRXksjr+UGshOYrwEnpZTW59v9FPhgfqwbyaaXfLDgYb5KNmr9ryOO/QWyKSh/ne/zHLKQ/eHt/RySOk+l0ZioazUkSZKk6c2RZ0mSJKkgw7MkSZJUkOFZkiRJKsjwLEmSJBVkeJYkSZIKmjL3eR4cHGzU6625M0itVqFVx9bksI87g/3cGeznzmA/T3+t7OPu7toyYNFo66ZMeK7XG6xcub4lx+7rm9WyY2ty2MedwX7uDPZzZ7Cfp79W9vGiRXPvGGud0zYkSZKkggzPkiRJUkGGZ0mSJKkgw7MkSZJUkOFZkiRJKsjwLEmSJBVkeJYkSZIKMjxLkiRJBRmeJUmSpIIMz5IkSVJBpYbniDgqIn42SvupEfH/IuLqiHhdmTVIkiRJE6WrrB1HxLuBVwLrRrR3A58GjszXXRkRl6aU7i+rlh2x9KF1rHtwHWvX9be6FJVozuzO6OODd53LvN7uVpchSdKUVVp4Bm4FXgT824j2A4GlKaWHASLiCuB44Nvj7axWq9DXN6uMOsdUH2zwF//0SzbXG5N6XKksLztiCee84AmtLqNlarXqpP87oslnP3cG+3n6a9c+Li08p5S+ExF7jbJqHrCqaXkNMH9b+6vXG6xcuX6CqivuO685kv5KlbVrN076sTV55szpnfZ9/J7v3sjKtf0t+T1qF319szr683cK+7kz2M/TXyv7eNGiuWOuK3PkeSyrgeaK5gIrW1BHIbvO6/UXtAN0Qh/P6PL6YEmSdlQrwvNNwH4RsROwFngq8IkW1CFJkiRtl0kLzxFxOjAnpXR+RLwD+AHZ3T6+nFK6Z7LqkDQ5Go0G9cEGA4MNNtcbbB4czF7rgwwMNhgYq60+yObB5rZ8m6G2eoOBwdHbToxFHLf3zq3+6JKkaazU8JxS+hNwdP7+603tlwKXlnlsSY/08PrNXHvHw2yqD7Kp3mDTwGD2Vc+/ht83trwft23ofRZi6yOCcllqFeiqVemuVeiqZq+bBga57OaH+OcXH8wRj+0r7dgqR6PRoN6AgaGTpqGv+iD1RiM/QdrytXjuDHae3dPqsiV1oFZM25DUAr3dNa69cyXX3rlym9t21yr01KrZV1eVnlolf82+uruqzJnRNbyuOw+y3dUqXflyV7Uyblt3rdIUgEdrG9rn1m1d1Qq1auURNa/ZOMBrv/k73nPpjfzLyw9lr53a7wrtMg02GsOj+JuHR+sH2Tyw9Qh/88nNQH3Lic/A4Ja/FAyF1uawWp+g9iwMPzIk1we372RrzwUz+c/XHFnST1OSxmZ4ljrEJ15wEHet3LB1IB5+X2VGV3U4BFcrjwyn7W5ubxeffuFBnPG13/H2i6/nKy9/En2zyrmndX2wwab6IP1NI/f9I0flBxr0Dy0PDG55n08z2TyYbTPQFGw35YHykSF4xHLTdtn+skBallo1O8EZ/qptOYkZrb2rWmFGV5XZo7TXxth+m+1NJ08X/f4+blm2btuFl6x5atLQtKOBwcERy1va6mO0j72ct9VHOSkZ0d58onLkY/t45ZF7tPrHI01bhmepQ+w2v5fd5ve2uoxS7T5/Jp887SDe+O3reNclN/DKI/egf6BO/0AWbqvdNVau6Wdj3jbalJSxAnH/QBZc+/PpKTuqVs1G1YdH7ZtG77da7qoye8Rofc9WI/lN2xfZX/59PV3V4b8KDO1ntDBcq0ClzU6mrv7TCm64fw0/X7p8q5OPzXnw7J7Rxeq1/U1t+Uj7YOMRbc3LzScuRUfXJ8vQVKVHnlRUt+qz+9f0c/fKDYZnqUSGZ0nTysG7zeNDzw7+5r9v4veX3DDqNtUKw6PtM7q2Hn0fGo1vnpbS3D5jlG23HsHPgumMEaP6Q++n8uh+u5jd08Wa/gHeNUb/NqvAVicNI08imtu6alV6u7dMFapVKsMnF6ONio8cEd+yvPUUo9Hax17O22pbh+SiJzDv/95N/OquVfz0lmWjXpw7dAIxNEq+y9wZvPiQ3XawR6TOYniWNO2cGIs44DFzWNM/MByQZ3TVeMzOs9m4rn+7wojazxuO3ZNn7Lcwm0s/PKd+yyj7wp1ms27NxrYdOS/TnBldLF+3iXd/98bC3/PsA3dhdo9xQCrK3xZJ09KSvpmPaJvb20194+YWVKOJ1Ntd4+Dd5o25vpP7+W1P25tTn7B4eArP0EW6XbVHXsT7zd/cw6d/dhuNyZt9Ik0LhmdJkqaJ3u4aBy0e+7HCknac4VmSJA3fPWTozjADgw0Wzu7pqGkvUhGGZ0mSOtipF/xvdtvDgUFGzuB4+9P35vTDl7SkLqldGZ4lSepAT9t3Z+56eAPVSv4QpK3uElPhUz+9lRXrt8wdrw82hm/l2N90W8fsfT2/pWMjez90i8d6g/7N9fzWjyPWDWy5HWTz+0YDPnDy/hy069jz2qVWMjxLktSBdp8/k/ecuN+Y6//p57fxzd/cw7d/e++E3N+8+UmlvUNhvas2fIvH2bN6aNDgqtsf5uYH1xqe1bYMz5Ik6RHe8tS9uWPF+q3uVd474p7nzfc9n9H1yHuhN98Pvci9zZet28RzvnDNJHw66dEzPEuSpEd4+WG7t7oEqS0ZniVJUlv512vv4ju/v4/+gUFm99T44ssOYWZ3rdVlSQBUW12AJEkSwIKZ3Zx8wCL2WDCT3eb1Mq+3i5seWMuytZtaXZo0zJFnSZLUFmrVCuc898Dh5e/f+ADX35daWJH0SI48S5KktlcfbLBu0wAD+V0/vvGNr3PYYQfxmMfM57DDDuI73/lWiytUp3DkWZIktaWhG3S87Ku/YnM9C82H7j6PZ3f/kXe+869Yv349AHfffRfveMdbAHjxi1/aklrVOQzPkiSpLR215wJOP3x3apUKM7tr/OLW5dy9ciMfOu+Dw8F5yIYNG/joRz9seFbpDM+SJKkt7TSrh7c/fZ/h5WXrNnHRdffxwH33jrr9PffcPVmlqYM551mSJE0Jrzt2T/7ueQeyaPFuo67fffclk1yROpHhWZIkTQkLZ/dwUizibz/4YWbNmrXVupkzZ/K+932wRZWpkxieJUnSlPLiF7+U8877Aj3zdwEqLFmyB5/61Oec76xJ4ZxnSZI05bz85afzz3cu5pi9duL9J+/f6nLUQRx5liRJkgoyPEuSJEkFGZ4lSZKkggzPkiRJUkGGZ0mSJKkgw7MkSZJUkOFZkiRJKsjwLEmSJBVkeJYkSZIKMjxLkiRJBRmeJUmSpIIMz5IkSVJBhmdJkiSpIMOzJEmSVJDhWZIkSSrI8CxJkiQVZHiWJEmSCjI8S5IkSQUZniVJkqSCDM+SJElSQYZnSZIkqSDDsyRJklSQ4VmSJEkqyPAsSZIkFWR4liRJkgoyPEuSJEkFGZ4lSZKkgrrK2nFEVIFzgUOAfuDMlNLSpvV/DrwTqANfTimdV1YtkiRJ0kQoc+T5NKA3pXQMcDbwyRHrPwGcCDwFeGdELCixFkmSJGmHlRmejwMuA0gpXQMcMWL9dcB8oBeoAI0Sa5EkSZJ2WGnTNoB5wKqm5XpEdKWUBvLl64FfA+uAi1JKK8fbWa1Woa9vVimFbkutVm3ZsTU57OPOYD93Bvu5M9RqVSrVCj0zuuzvaapdf5fLDM+rgblNy9Wh4BwRTwSeCzwOWAv8e0S8JKX07bF2Vq83WLlyfYnljq2vb1bLjq3JYR93Bvu5M9jPnaGvbxaNwQab+gfs72mqlb/LixbNHXNdmdM2rgROAYiIo4E/NK1bBWwANqSU6sCDgHOeJUmS1NbKHHm+GDgpIq4im9N8RkScDsxJKZ0fEV8EroiITcCtwIUl1iJJkiTtsNLCc0ppEDhrRPPNTeu/AHyhrONLkiRJE82HpEiSJEkFGZ4lSZKkggzPkiRJUkGGZ0mSJKkgw7MkSZJUkOFZkiRJKsjwLEmSJBVkeJYkSZIKMjxLkiRJBRmeJUmSpIIMz5IkSVJBhmdJkiSpIMOzJEmSVJDhWZIkSSrI8CxJkiQVZHiWJEmSCjI8S5IkSQV1tboASZKkR2tgcJC7V27g/tX9rO4f4LjH7URPl2ODKo/hWZIkTVnfu/FBvnfjg8PLH3/+4zlhv4UtrEjTneFZkiRNSX/11L3504r17DqvlwYNzvnhLWyuD7a6LE1zhmdJkjQlnXzgLsPv/7R8fQsrUSdxUpAkSZJUkOFZkiRJKsjwLEmSJBVkeJYkSZIK8oJBSZI0bXzn9/dx6fUPcO/qjfTUqvzrK55Ed82xQk0c/2uSJElT3oJZ3cyd0cXty9ezun+AnlqVpcvWsa6/3urSNM048ixJkqa8+TO7ufwvj6FSqQDwrd/ewz/+5NYWV6XpyJFnSZI0LQwFZ6lMhmdJkiSpIMOzJEmSVJDhWZIkSSrI8CxJkiQVZHiWJEmSCjI8S5IkSQUZniVJkqSCDM+SJElSQYZnSZIkqSDDsyRJklSQ4VmSJEkqyPAsSZIkFWR4liRJkgoyPEuSJEkFGZ4lSZKkggzPkiRJUkGGZ0mSJKkgw7MkSZJUkOFZkiRJKsjwLEmSJBVkeJYkSZIKMjxLkiRJBRmeJUmSpIK6ytpxRFSBc4FDgH7gzJTS0qb1RwKfAirA/cArUkoby6pHkiRJ2lFljjyfBvSmlI4BzgY+ObQiIirABcAZKaXjgMuAPUusRZIkSdphpY08A0OhmJTSNRFxRNO6/YHlwNsi4mDgeymlNN7OarUKfX2zSit2/GNXW3ZsTQ77uDPYz53Bfu4M2+rnmTN7AJg3fyZ9s3smqyxNoHb9XS4zPM8DVjUt1yOiK6U0ACwEjgXeAtwC/HdE/DqldPlYO6vXG6xcub7EcsfW1zerZcfW5LCPO4P93Bns586wrX7esGETAKtXbaC6eWCyytIEauXv8qJFc8dcV+a0jdVA85GreXCGbNR5aUrpxpTSZrIR6sNLrEWSJEnaYWWG5yuBUwAi4mjgD03rbgPmRMS++fLxwA0l1iJJkiTtsDKnbVwMnBQRV5HdUeOMiDgdmJNSOj8iXgt8Pb948KqU0vdKrEWSJEnaYaWF55TSIHDWiOabm9b/BHhyWceXJEmSJpoPSZEkSZIKMjxLkiRJBRWethERTwN2Ipu/DEBK6aIyipIkSZLaUaHwHBEXAM8BlgKNvLkBGJ4lSZLUMYqOPD8TODCltKbMYiRJkqR2VnTO810GZ0mSJHW6oiPPV0bEN4FLgQ1Djc55liRJUicpGp6PyV/PbGpzzrMkSZI6SqHwnFI6ASAiuoBKSmlzqVVJkiRJbajQnOeI2CUi/gdYB2yMiJ9ExG7lliZJkiS1l6IXDP4zcA3wGGAX4JfAeWUVJUmSJLWjonOe908pvbRp+YMRcUMZBUmSJEntqujIc3dE9A4tRMQstjwsRZIkSeoIRUeevwn8OCK+QhaaXwP8Z2lVSZIkSW2o6N02PhIRdwPPBmrAhcC/lFiXJEmS1HbGDc8RMS+ltDoidgIuyb+GLABWlFmcJEmS1E62NfL8M+AwYBlbz3Gu5Mu1csqSJEmS2s+44TmldFj+WvTCQkmSJGnaKvqQlMdExPPz938fEZdHxBPLLU2SJElqL0VHlC8E9omIZwDPAf4N+FxZRUmSJEntqGh43jml9Gmy4Pz1lNKFwKzSqpIkSZLaUNHw3BMR3WTh+cf5Q1LmlFeWJEmS1H6KhudLgIeAZSmlXwPXAl8vrSpJkiSpDRUKzymlDwJPAE7Im05PKX2ktKokSZKkNjRueI6IV+Sv7wBeCrw9f39i/ipJkiR1jG09JGW//PXgsguRJEmS2t24I8/5dA1SSmcAX8lf3wlckr+XJEmSOkbRh6ScA3w4X5wFnB0R7y+tKkmSJKkNFb3bxmnAswBSSncDTwP+rKSaJEmSpLZUNDx3p5Q2Ny1vAgZLqEeSJElqW9u6YHDIlRHxNeBfgAbwKuB/S6tKkiRJakNFR57fAjwAfBr4RP7+rWUVJUmSJLWjQiPPKaV1wDsiYkFK6eGSa5IkSZLaUqHwHBEBXAzMj4gjgcuBF6aUbi6zOEmSJKmdFJ228TmyaRoPppTuzZfPL60qSZIkqQ0VDc87p5R+NLSQUjoXmFdOSZIkSVJ7KhqeGxHRS3anDSJiMVArrSpJkiSpDRUNz+cBPwB2iYiPAdcA55ZWlSRJktSGit5t418i4hbguUA38LrmaRySJElSJyh6t43LU0rPBH5Rcj2SJElS2yo6baMvImaXWokkSZLU5oo+nnsdcEdEXAesHWpMKT2/lKokSZKkNrTN8BwRTwAuIbtg8O7SK5IkSZLa1LjhOSLOAD4J3ALsA/x5SukHk1GYJEmS1G62Nef5r4AnpJSOAk4F3lN+SZIkSVJ72uYFg/njuEkpXQ0sKr0iSZIkqU1tKzw3RiwPlFWIJEmS1O6K3qpuyMgwLUmSJHWMbd1t44kRsbppeVa+XAEaKaV55ZUmSZIktZdthed9JqUKSZIkaQoYNzynlO6YrEIkSZKkdlf0CYPbLSKqwLnAIUA/cGZKaeko250PrEgpnV1WLZIkSdJE2N4LBrfHaUBvSukY4Gyyh61sJSLeABxcYg2SJEnShClt5Bk4DrgMIKV0TUQc0bwyIo4Bjga+CBxQYh2SJKlDfee6e1m+bjN3PbyBw/eYz6uPemyrS9IUV2Z4ngesalquR0RXSmkgInYFPgS8EHhpkZ3VahX6+mZNfJWFjl1t2bE1OezjzmA/dwb7uTNsq58X5eu+cOUdzJnRxWCjwcr+Ad52suN1U0W7/i6XGZ5XA3OblqsppaGHrLwEWAh8H1hMdgu8m1NKF461s3q9wcqV68uqdVx9fbNadmxNDvu4M9jPncF+7gzb6ufj9+zja688jEVzeuib2c1fX3Ij967e6H8bU0grf5cXLZo75royw/OVwKnAtyLiaOAPQytSSp8FPgsQEa8GDhgvOEuSJG2PrmqF/XeZ0+oyNA2VGZ4vBk6KiKvIHqpyRkScDsxJKZ1f4nElSZKkUpQWnlNKg8BZI5pvHmW7C8uqQZIkSZpIZd6qTpIkSZpWDM+SJElSQWXOeZYkSWobjQbcu2ojd63cwAOr+znmcQtYNGdGq8vSFGN4liRJ016lAkuXreMFX7p2uO2p++zMwbvO5e5VG1mzcYD3nLgvO83qaWGVmgoMz5Ikado7/fAl7LXTLHaf38seC2byN5fexC9uXc4vbl3O7J4a6zbVecHBizn2cTu1ulS1OcOzJEma9p60ZD5PWjJ/ePnLpx/K+k11du/r5bZl63nNN37XuuI0pRieJUlSx1nSN7PVJWiK8m4bkiRJUkGGZ0mSJKkgw7MkSZJUkOFZkiRJKsjwLEmSJBVkeJYkSZIKMjxLkiRJBRmeJUmSpIJ8SIokSRLQAB5ev4l7V21kRneNfRfObnVJakOGZ0mSJOBd/3UDA4MNAGZ0Vfn5W55CrVppcVVqN4ZnSZLU0fZbNJsXHLyYmd01dpvfy3X3rObHf3yIRqsLU1syPEuSpI7W213j/c/af3h5/aYBfvzHFhaktuYFg5IkSVJBhmdJkiSpIMOzJEmSVJDhWZIkSSrI8CxJkiQVZHiWJEmSCjI8S5IkSQV5n2dJkqRRXHHrch5c28/9q/s5cs8+jtlrp1aXpDZgeJYkSWrSU8v+MP/X371xuO3GB9YYngUYniVJkrbywifuymMXzGTn2T0sntfLey+9kYbP6lbO8CxJktRkzowunrbvwuHlSqXSwmrUbrxgUJIkSSrI8CxJkiQVZHiWJEmSCjI8S5IkSQUZniVJkqSCDM+SJElSQYZnSZIkqSDDsyRJklSQ4VmSJEkqyPAsSZIkFWR4liRJkgoyPEuSJEkFGZ4lSZKkggzPkiRJUkGGZ0mSJKkgw7MkSZJUkOFZkiRJKqir1QVIkiS1u831Bvev3siydZt4cE0/82d2s25TnWXrNjFQb/CiQ3alq1ppdZmaBIZnSZKkcVQq8If7VnPqBdeOuc1Bu87loMVzJ7EqtYrhWZIkaRyvP3ZPfn3XKhbO7mHh7B6Wr9vEglndLJzdw+0r1vPhy/7I4GCj1WVqkhieJUmSxnHYkj4OW9I36rpVGwcmtxi1nBcMSpIkSQWVNvIcEVXgXOAQoB84M6W0tGn9y4G3AXXgOuBNKaXBsuqRJEmSdlSZI8+nAb0ppWOAs4FPDq2IiJnAOcAJKaVjgfnA80qsRZIkSdphZc55Pg64DCCldE1EHNG0rh84NqW0vqmOjePtrFar0Nc3q5RCt6VWq7bs2Joc9nFnsJ87g/3cGdqln+fMWZe9zu1ti3qmk3bp45HKDM/zgFVNy/WI6EopDeTTMx4AiIi3AHOAH423s3q9wcqV68fbpDR9fbNadmxNDvu4M9jPncF+7gzt0s9r1/Znr2s2tkU900kr+3jRorFvO1hmeF4NNB+5mlIaviQ1nxP9cWB/4MUpJe/xIkmSpLZW5pznK4FTACLiaOAPI9Z/EegFTmuaviFJkiS1rTJHni8GToqIq4AKcEZEnE42ReNXwGuBXwI/iQiAz6SULi6xHkmSJGmHlBae83nNZ41ovrnpvfeYliRJ0pRigJUkSZIKMjxLkiRJBRmeJUmSpIIMz5IkSVJBhmdJkiSpIMOzJEmSVJDhWZIkSSrI8CxJkiQVZHiWJEmSCjI8S5IkSQWV9nhuSZKkTnHV7Su4Z9VGVm/czG7zezlu751bXZJKYniWJEl6lGZ21wD40jV3DrfNmVHjp29+SqtKUskMz5IkSY/SIbvP44KXHUKtWmFubxff+PU9/M9ND7S6LJXI8CxJkvQoVSsVDl0yf3h5aCRa05fhWZIkaQJt2DzIfas3smbjAGv6B9h34Wzmz+xudVmaIIZnSZKkCVKrVgB4/gXXDrc9+8Bd+MgpB7SqJE0ww7MkSdIEecmhu7Lz7G7m9HQxp7eLz/z8NjZsqre6LE0gw7MkSdIEWTyvl9MPXzK8/KWr72hhNSqDD0mRJEmSCjI8S5IkSQUZniVJkqSCnPMsSZJUkkYDfn7rct7z3RtZv6nOpvog7zhhH2KXOa0uTY+SI8+SJEkledKS+ew8u4fbV6xn5YbN/ObuVfz+nlWtLks7wJFnSZKkkrz7mfvy7mfuC8DK9Zs56byrW1yRdpQjz5IkSVJBhmdJkiSpIMOzJEmSVJDhWZIkSSrI8CxJkiQVZHiWJEmSCjI8S5IkSQUZniVJkqSCDM+SJElSQT5hUJIkaRL9409u5fyr7qB/YJBZPTW+fcYRzOvtbnVZKsjwLEmSNAnmz+ziVU/egxXrNjGjq8p9q/u58vYVrFi32fA8hRieJUmSJkGlUuHNxz9uePmHNz/IlbevaGFFejSc8yxJkiQVZHiWJEmSCjI8S5IkSQUZniVJkqSCDM+SJElSQYZnSZIkqSDDsyRJklSQ93mWJElqofd+7yaW9M1koD7IIbvP51VP3qPVJWkcjjxLkiS1wD4LZ7PPwln0Dwxyx4r1/P7e1Xzrt/e0uixtgyPPkiRJLbDPwtl881VHDC+f84M/csn193PV7SsYbDQYbMATd5tH30wf3d1ODM+SJEltYFZPDYC3XnT9Vu17LpjJYKNBV7XKR593APstmtOK8pQzPEuSJLWBNx23F8/YbyHVaoVaBS694QEeXr+ZaqXCxoE6V9y2glseWmd4bjHDsyRJUhvo7a5x6JL5w8sH7Tpv+P1dD2/gittW8PHLl/Kbu1Yx2Giwpn+Ak2IRAIMNaNCg0YDBRoP6YIMFs3rom9lNo9FgRleV2GUOlUpl0j/XdGN4liRJanM7z+5h751nsWL9Zq760woeWrsJgJ8tXV54Hyfst5Aj9phPpVKhWiF7BSoVOGS3+ey186ySqp9eDM+SJEltblZPjf949ZaLCxuNBnc+vIF6o0GVClSgmodigAfW9LNxYJBqBR5as4mP/PCP/PSWZfz0lmVjHuPgXefSAAbqDRbPm8FBi7Pltf11Dtp1LrUKNBqwe19vR08dKS08R0QVOBc4BOgHzkwpLW1afyrwAWAA+HJK6YKyapEkSZpOKpUKe+409kjxkr6ZWy0/64BF9A8MZtM6yO7k0cjv6PHfN9zPb+5aRaUCFSpcc8fD3Pzg2nFHtWsVaJBNFwHYdd4MBhuwaWCQrlpeW6PBivWbOfUJi+mpZXdHXjxvBk/cbct0lPm9XVNuKkmZI8+nAb0ppWMi4mjgk8ALACKiG/g0cCSwDrgyIi5NKd1fYj2SJEkdqbe7Rm93bdR1rz16T1579JblgcEGA/VBIAvpd6/cwKb6IBXg3lUbuf6+NXTVKlSA9OA65s/sYij+/uquVSyeO4OB+iC3LlvPmv4BPvPz28atbc8FM/OLJCtUKlCrVKhWK+y582w+dPJ+VNssXJcZno8DLgNIKV0TEUc0rTsQWJpSehggIq4Ajge+XWI9kiRJ2oauaoWu6pagvc/C2cPvD3jMXJ6x/6LC+1q9cTOb6w0qlWwqye/uWT38hL5f3bWSGV1V6oPk97XORsKHLnic27sllLeTMsPzPGBV03I9IrpSSgOjrFsDzGcctVqFvr7WTGSv1aotO7Ymh33cGeznzmA/dwb7eWroa3q/N3BMPGZ4+Q3b+N5arUo9HwFvJ2WG59XA3Kblah6cR1s3F1g53s7q9QYrV66f0AKL6uub1bJja3LYx53Bfu4M9nNnsJ+nv1b28aJFc8dcVx1zzY67EjgFIJ/z/IemdTcB+0XEThHRAzwVuLrEWiRJkqQdVubI88XASRFxFVABzoiI04E5KaXzI+IdwA/IAvyXU0r3lFiLJEmStMNKC88ppUHgrBHNNzetvxS4tKzjS5IkSROtzGkbkiRJ0rRieJYkSZIKMjxLkiRJBRmeJUmSpIIMz5IkSVJBhmdJkiSpIMOzJEmSVJDhWZIkSSrI8CxJkiQVVGk0Gq2uoaiHgDtaXYQkSZKmvT2BRaOtmErhWZIkSWopp21IkiRJBRmeJUmSpIIMz5IkSVJBhmdJkiSpIMOzJEmSVFBXqwtoFxFRBc4FDgH6gTNTSkub1p8KfAAYAL6cUrqgJYVqhxTo55cDbwPqwHXAm1JKgy0oVTtgW/3ctN35wIqU0tmTXKJ2UIHf5SOBTwEV4H7gFSmlja2oVY9egX7+c+CdZP9mfzmldF5LCtUOi4ijgH9IKT19RHvb5S9Hnrc4DehNKR0DnA18cmhFRHQDnwaeBTwNeH1ELG5FkdphpzF2P88EzgFOSCkdC8wHnteKIrXDTmOMfh4SEW8ADp7kujRxTmPs3+UKcAFwRkrpOOAysnu2auo5jfF/lz8BnAg8BXhnRCyY3PI0ESLi3cCXgN4R7W2ZvwzPWwz9A0tK6RrgiKZ1BwJLU0oPp5Q2AVcAx09+iZoA4/VzP3BsSml9vtwFOFI1NY3Xz0TEMcDRwBcnvzRNkPH6eH9gOfC2iPg5sFNKKU1+iZoA4/4uk/2FcD5Z6KoAPrxiaroVeNEo7W2ZvwzPW8wDVjUt1yOia4x1a8h+WTX1jNnPKaXBlNIDABHxFmAO8KPJL1ETYMx+johdgQ8Bf9mCujRxxvs3eyFwLNmf+08EnhkRz5zk+jQxxutngOuBXwM3AP+dUlo5ibVpgqSUvgNsHmVVW+Yvw/MWq4G5TcvVlNLAGOvmAisnqS5NrPH6mYioRsQngJOAF6eUHMWYmsbr55eQhavvk/0Z+PSIePXklqcJMF4fLycbrboxpbSZbOTy8MkuUBNizH6OiCcCzwUeB+wF7BIRL5n0ClWmtsxfhuctrgROAYiIo4E/NK27CdgvInaKiB7gqcDVk1+iJsB4/QzZn/F7gdOapm9o6hmzn1NKn00pHZ5flPL3wNdTShe2okjtkPF+l28D5kTEvvny8WQjk5p6xuvnVcAGYENKqQ48CDjneXppy/xVaTQcWIOtruh9Itm8qTOAw4A5KaXzm672rJJd7fn5lhWrR228fgZ+lX/9ki3z5j6TUrq4BaVqB2zr97lpu1cDB3i3jamnwL/ZzyA7OaoAV6WU3tqyYvWoFejns4DXAJvI5s2+Lp8bqykmIvYCvplSOjoiTqeN85fhWZIkSSrIaRuSJElSQYZnSZIkqSDDsyRJklSQ4VmSJEkqyPAsSZIkFdS17U0kSa0SEQ2yp6jVyW6hOIvswQFvTCn9aoKPtRdwfUppTkR8CFiYUnrzRB5DkqY6w7Mktb8TUkrLhhYi4l3A54BjWleSJHUmw7MkTSER0QU8FljR1PY+4MVkU/H+BLwppXRvRCwGvgAcAAwCX0gpfTZ/UtvHgRnArsCPUkqvndQPIklTlHOeJan9/TQirouIe4E/5m1nAETEXwAHA09OKR0KfB/4Ur7NucAfU0oHkI1Svz5/ZPVbgQ+klI4CHg88PyIOn7RPI0lTmCPPktT+TkgpLYuIw8jC8U9TSg/m654HPBn4VUQA1MjmRQOcCLwbIKW0CngCQES8CjglIt5LNio9k+wR9csn5+NI0tTlyLMkTREppd8AbwcuzC/ugyws/0NK6dB85PkI4Cn5ugGyiwwBiIi9I2Ie8AvgFOBm4G+Be4DKZHwGSZrqDM+SNIWklL4BXAt8Om/6AXBmHoohC8P/lr//MVumd8wHLgf2A44E3pNSughYAuxLFsIlSdvgtA1JmnreDFwXESeTzW/eHbgmv63dncCrm7Y7LyKuIxss+VhK6dcR8THgNxGxDrgbuJIsQN86uR9DkqaeSqPR2PZWkiRJkpy2IUmSJBVleJYkSZIKMjxLkiRJBRmeJUmSpIIMz5IkSVJBhmdJkiSpIMOzJEmSVJDhWZIkSSro/wN8ie0iZZ+13wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "precision, recall, threshold = precision_recall_curve(y_test, proba[:,1])\n",
    "\n",
    "f2score = (5 * precision * recall) / (4 * precision + recall)\n",
    "idx = np.argmax(f2score)\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(recall, precision)\n",
    "plt.plot(recall[idx], precision[idx], marker='o', color='black')\n",
    "plt.title('Precision-Recall Curve', fontsize=15)\n",
    "plt.xlabel('Recall', fontsize=12)\n",
    "plt.ylabel('Precision', fontsize=12);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ef11a448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.29377979812347543\n",
      "Recall:    0.803680981595092\n",
      "Precision: 0.916083916083916\n",
      "F1-score:  0.8238993710691823\n"
     ]
    }
   ],
   "source": [
    "print(f'Threshold: {threshold[idx]}')\n",
    "print(f'Recall: {recall[idx]:20}')\n",
    "print(f'Precision: {precision[idx]}')\n",
    "print(f'F1-score: {f2score[idx]:19}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "79184bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_idx = np.where(recall >= recall_score(y_test, predictions))\n",
    "recall = recall[recall_idx]\n",
    "precision = precision[recall_idx]\n",
    "threshold = threshold[recall_idx]\n",
    "\n",
    "precision_idx = np.where(precision >= precision_score(y_test, predictions))\n",
    "recall = recall[precision_idx]\n",
    "precision = precision[precision_idx]\n",
    "threshold = threshold[precision_idx]\n",
    "\n",
    "f2score = (5 * precision * recall) / (4 * precision + recall)\n",
    "idx = np.argmax(f2score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e927634f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.39414758269720096\n",
      "Recall:    0.7852760736196319\n",
      "Precision: 0.9481481481481482\n",
      "F1-score:  0.8132147395171537\n"
     ]
    }
   ],
   "source": [
    "print(f'Threshold: {threshold[idx]}')\n",
    "print(f'Recall: {recall[idx]:21}')\n",
    "print(f'Precision: {precision[idx]}')\n",
    "print(f'F1-score: {f2score[idx]:19}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "de134d4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[85273,     7],\n",
       "       [   35,   128]], dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_predictions = np.where(proba[:,1] >= threshold[idx], 1, 0)\n",
    "confusion_matrix(y_test, new_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b8ca78e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8132147395171537"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fbeta_score(y_test, new_predictions, beta=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8d567531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost: RM 323.75\n"
     ]
    }
   ],
   "source": [
    "(tn, fp), (fn, tp) = confusion_matrix(y_test, new_predictions)\n",
    "\n",
    "print(f'Cost: RM {round(fn * fraud_cost, 2)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
